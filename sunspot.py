# -*- coding: utf-8 -*-
"""Sunspot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QBbvEGdpdgRv-cFsip3NTTjQDTtA6X-x

<h1 align=center>Deep Learning-Based Sunspot Forecasting: An RNN Approach</font></h1>

<br>

<p align="center">
    <img src="https://images.csmonitor.com/csm/2013/02/sunspot.jpg?alias=standard_900x600" height=450 width=2000 alt="Sakilar">
</p>

<small>Picture Source: <a href="https://www.csmonitor.com/Science/2013/0221/Sunspots-Huge-and-growing-fast-says-NASA">csmonitor</a></small>

<br>

<h2>Abstract</h2>

<p>Understanding and predicting solar activity, such as sunspots, is crucial in the context of space weather forecasting. Solar phenomena impact various technological systems, including satellite communications and power grids. In this study, we explore the application of advanced machine learning models, specifically Recurrent Neural Networks (RNNs), to improve the forecasting of sunspot activity. Leveraging the temporal dependencies inherent in solar data, our RNN-based approach aims to provide more accurate and timely predictions, enhancing our ability to mitigate the potential effects of solar events on Earth's technological infrastructure.</p>

<br>

<h2>Context</h2>

<p>In the realm of space weather, the prediction of solar phenomena plays a vital role in safeguarding technological assets on Earth. Sunspots, which are temporary and dark regions on the sun's surface, serve as crucial indicators of solar activity. These phenomena have far-reaching implications for various technological systems, including radio communication, navigation systems, and power distribution. The number and behavior of sunspots influence space weather, impacting Earth's magnetosphere and ionosphere. With an increasing dependence on technology, accurate forecasting of sunspot activity becomes essential for mitigating potential adverse effects on our interconnected systems.</p>

<br>

<p>Traditional methods of sunspot prediction often struggle to capture the intricate and dynamic patterns in solar data. This limitation has spurred the exploration of advanced machine learning techniques to improve prediction accuracy. Recurrent Neural Networks (RNNs), known for their proficiency in modeling sequential data, emerge as a promising solution. The temporal nature of sunspot activity, characterized by cycles and variations, aligns well with the strengths of RNNs. This study focuses on harnessing the capabilities of RNNs to enhance sunspot forecasting accuracy, contributing to the resilience of Earth's technological infrastructure against the impacts of space weather events.</p>


<br>

<h2>Dataset</h2>

Our analysis is based on the [Sunspot Index and Long-term Solar Observations Dataset (Yearly total sunspot number)](https://www.sidc.be/SILSO/datafiles) that provides comprehensive data on sunspot activity. This dataset, collected by the SOHO spacecraft, serves as a valuable resource for training and evaluating our machine learning models.

<br>

<h2>Keywords</h2>
<ul>
  <li>Sunspot Forecasting</li>
  <li>Recurrent Neural Networks (RNN)</li>
  <li>Space Weather Prediction</li>
  <li>Solar Activity Modeling</li>
  <li>Sunspot Index and Long-term Solar Observations Dataset</li>
</ul>

<br>

<h2>Table of Contents</h2>

<div class="alert alert-block alert-info" style="margin-top: 20px">
<li><a href="">Importing Libraries</a></li>
<li><a href="">Preparing Data for Sunspot Forecasting</a></li>
<li><a href="">Building RNN Model for Forecasting Sunspots</a></li>

<br>

## Importing Libraries
"""

import os
import csv
import datetime

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from dataclasses import dataclass

import tensorflow as tf

"""## Preparing Data for Sunspot Forecasting"""

file_path = '/content/SN_y_tot_V2.0.csv'

"""### Data Preprocessing

Data preprocessing is a critical initial step in data analysis and machine learning. It encompasses tasks like handling missing values, removing duplicates, correcting errors, scaling and normalizing data, encoding categorical variables, and selecting relevant features. Outliers are identified and managed, and time series data is appropriately treated. Data is often divided into training, validation, and testing sets, and methods are applied to address imbalances in classification datasets. This process is essential as it directly influences the quality and effectiveness of subsequent analyses or machine learning models, providing a strong foundation for deriving meaningful insights and building reliable predictive models.
"""

column_names = [
    "Year",
    "Sunspot",
    "Std Dev",
    "Observations",
    "Marker"
]

df = pd.read_csv(file_path, delimiter=';', header=None, names=column_names)

"""The column names are "Year" for the Gregorian calendar year, "Sunspot" for the yearly mean total sunspot number, "Std Dev" for the yearly mean standard deviation, "Observations" for the number of observations, and "Marker" for the definitive/provisional marker."""

df.head()

df.shape

df.info()

df.describe().T

df.isnull().sum()

"""After arrange the DataFrame for the training, we proceeded to save this refined dataset for future calculations and analyses. The Pandas library provides a convenient method for this purpose."""

df.to_csv('/content/SN_y_tot_V2.0_MODIFIED.csv', index=False)

"""## Building RNN Model for Forecasting Sunspots

In the pursuit of a deeper understanding and more accurate predictions of solar activity, we embark on a data-driven exploration to construct an innovative forecasting model. Our focus is on developing a state-of-the-art Recurrent Neural Network (RNN) tailored specifically for forecasting sunspot trends. Drawing upon the capabilities of deep learning, this project aims to elevate our comprehension of solar dynamics, offering insights into the intricate patterns of sunspot activity. From the vast expanse of space, where sunspots play a pivotal role, to their potential impacts on Earth's technological infrastructure, our RNN-based model seeks to provide more precise and timely predictions. This journey encompasses data preprocessing, model design, rigorous training, and comprehensive evaluation, all with the overarching goal of advancing our ability to predict and understand sunspot activityâ€”a key component in space weather forecasting and its implications for our technological systems.

### Building Functions
"""

def plot_series(time, series, format="-", start=0, end=None, label=None):
    plt.plot(time[start:end], series[start:end], format, label=label)
    plt.xlabel("Time")
    plt.ylabel("Sunspot Number $S_{n}$")
    plt.grid(True)

def parse_data_from_file(filename):

  times = []
  sunspots = []

  with open(filename) as csvfile:

      reader = csv.reader(csvfile, delimiter=',')

      next(reader)

      step=0
      for row in reader:
          sunspots.append(float(row[1]))
          times.append(step)
          step = step + 1

  return times, sunspots

"""We defined train-val split as 0.8 and 0.2:"""

round(df.shape[0] * 0.8)

"""1. **SUNSPOTS_CSV** is a class attribute that stores the file path '/content/SN_y_tot_V2.0_MODIFIED.csv' presumably a CSV file containing sunspots data.

2. **times** and **sunspots** are two variables that are initialized by calling a function parse_data_from_file(SUNSPOTS_CSV). It appears that this function reads and parses data from the specified CSV file, resulting in lists of time and sunspots values.

3. **TIME** and **SERIES** are two class attributes that store NumPy arrays created from the times and sunspots data, respectively. This conversion to NumPy arrays is likely for more efficient data manipulation and analysis.

4. **SPLIT_TIME** is a class attribute with a value of `round(df.shape[0] * 0.8)`. It could be a marker used for splitting the data into training and testing sets.

5. **WINDOW_SIZE**, **BATCH_SIZE**, and **SHUFFLE_BUFFER_SIZE** are class attributes that store constants or hyperparameters for use in a machine learning model or data preprocessing. These values may be used for tasks like defining the window size for data sequences, batch size for training, and buffer size for shuffling the data.
"""

@dataclass
class G:
    SUNSPOTS_CSV = '/content/SN_y_tot_V2.0_MODIFIED.csv'
    times, sunspots = parse_data_from_file(SUNSPOTS_CSV)
    TIME = np.array(times)
    SERIES = np.array(sunspots)
    SPLIT_TIME = round(df.shape[0] * 0.8)
    WINDOW_SIZE = 11
    BATCH_SIZE = 8
    SHUFFLE_BUFFER_SIZE = min(500, df.shape[0])

def train_val_split(time, series, time_step=G.SPLIT_TIME):

    time_train = time[:time_step]
    series_train = series[:time_step]
    time_valid = time[time_step:]
    series_valid = series[time_step:]

    return time_train, series_train, time_valid, series_valid

plt.figure(figsize=(15, 6))
plot_series(G.TIME, G.SERIES)
plt.show()

plt.figure(figsize=(15, 6))
plot_series(G.TIME[:G.SPLIT_TIME], G.SERIES[:G.SPLIT_TIME], label="Train Data")
plot_series(G.TIME[G.SPLIT_TIME:], G.SERIES[G.SPLIT_TIME:], label="Validation Data")
plt.legend()
plt.show()

time_train, series_train, time_valid, series_valid = train_val_split(G.TIME, G.SERIES)

time_train.shape

time_valid.shape

"""The `windowed_dataset` function processes time series data for training RNNs with TensorFlow. It creates a dataset using **TensorFlow's tf.data.Dataset API**, where each element consists of a window of data points and the corresponding target value. The function slides a fixed-size window (`window_size`) along the time series, shuffles the dataset for randomness, and batches the data for efficient training. It prefetches one batch for optimization. This utility function is designed to streamline the preparation of input data for RNN models, enabling them to learn sequential patterns in time series data. Adjustments to parameters like `batch_size`, `shuffle_buffer`, and `window_size` can be made based on specific model and dataset requirements."""

def windowed_dataset(series, window_size=G.WINDOW_SIZE, batch_size=G.BATCH_SIZE, shuffle_buffer=G.SHUFFLE_BUFFER_SIZE):

    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1]))
    ds = ds.batch(batch_size).prefetch(1)

    return ds

train_set = windowed_dataset(series_train, window_size=G.WINDOW_SIZE, batch_size=G.BATCH_SIZE, shuffle_buffer=G.SHUFFLE_BUFFER_SIZE)

"""### Building RNN Model

Our model architecture starts with a convolutional layer for local feature extraction, followed by two LSTM layers for capturing temporal dependencies, and concludes with a stack of dense layers for making predictions. This architecture is commonly used for time series forecasting tasks, and it's a combination of convolutional and recurrent neural networks to effectively model and predict sequences of data points. After defining this model, you would typically compile it with an appropriate loss function, optimizer, and metrics before training it on your data.
"""

def create_uncompiled_model():

    model = tf.keras.models.Sequential([
      tf.keras.layers.Conv1D(filters=64, kernel_size=3,
                          strides=1,
                          activation="relu",
                          padding='causal',
                          input_shape=[None, 1]),
      tf.keras.layers.LSTM(128, return_sequences=True),
      tf.keras.layers.LSTM(64, return_sequences=True),
      tf.keras.layers.LSTM(64),
      tf.keras.layers.Dense(30, activation="relu"),
      tf.keras.layers.Dense(10, activation="relu"),
      tf.keras.layers.Dense(1)
    ])

    return model

uncompiled_model = create_uncompiled_model()

uncompiled_model.summary()

for X, y in train_set.take(1):

    # Generate a prediction
    print(f'Testing model prediction with input of shape {X.shape}...')
    y_pred = uncompiled_model.predict(X)

y_pred_shape = y_pred.squeeze().shape

tf.keras.backend.clear_session()

"""Huber loss, also known as the Huber loss function, is a type of loss function used in machine learning, particularly in regression problems. It is designed to address some of the shortcomings of other loss functions like mean squared error (MSE), particularly when dealing with outliers in the data.

<br>

$$
L(y, f(x)) =
\begin{cases}
  \frac{1}{2}(y - f(x))^2 & \text{if } |y - f(x)| \leq \delta \\
  \delta(|y - f(x)| - \frac{1}{2}\delta) & \text{if } |y - f(x)| > \delta
\end{cases}
$$

<br>

When the absolute error $(|y - f(x)|)$ between the true target value $(y)$ and the predicted value by the model $f(x)$ is less than or equal to a threshold value $(\delta)$, the loss is calculated as:

<br>

$$ L(y, f(x)) = \frac{1}{2}(y - f(x))^2 $$

In this regime, the loss behaves like the squared error loss, similar to the mean squared error (MSE).

When the absolute error is greater than the threshold $(|y - f(x)| > \delta)$, the loss is calculated as:

<br>

$$ L(y, f(x)) = \delta(|y - f(x)| - \frac{1}{2}\delta) $$

In this regime, the loss becomes linear and increases with the absolute error, similar to the mean absolute error (MAE).

"""

def create_model():

    model = create_uncompiled_model()

    learning_rate = 5e-5

    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)
    model.compile(loss=tf.keras.losses.Huber(),
                  optimizer=optimizer,
                  metrics=["mae"])

    return model

model = create_model()

history = model.fit(train_set, epochs=100)

"""Within the context of forecasting, the model_forecast function is designed to make predictions using a given model and a time series dataset. This function processes the input time series, creating a data pipeline to prepare the data for forecasting. It employs windowing techniques to extract sequences of data, batches the sequences, and then utilizes a trained machine learning model to generate forecasts. The resulting predictions are essential for understanding and anticipating future trends and patterns within the time series data, providing valuable insights for various forecasting applications."""

def model_forecast(model, series, window_size):

    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size))
    ds = ds.batch(32).prefetch(1)
    forecast = model.predict(ds)

    return forecast

rnn_forecast = model_forecast(model, G.SERIES, G.WINDOW_SIZE).squeeze()

rnn_forecast = rnn_forecast[G.SPLIT_TIME - G.WINDOW_SIZE:-1]

plt.figure(figsize=(15, 6))
plot_series(time_valid, series_valid, label='Validation')
plot_series(time_valid, rnn_forecast, label='RNN Forecast')
plt.legend()
plt.show()

plt.figure(figsize=(15, 6))
plot_series(time_valid[50:], series_valid[50:], label='Validation')
plot_series(time_valid[50:], rnn_forecast[50:], label='RNN Forecast')
plt.legend()
plt.show()

"""Last 15 years of sunspots (average) year by year:"""

rnn_forecast[50:]

series_valid[50:]

mse = tf.keras.metrics.mean_squared_error(series_valid, rnn_forecast).numpy()
mae = tf.keras.metrics.mean_absolute_error(series_valid, rnn_forecast).numpy()
print(f"MSE: {mse:.2f}, MAE: {mae:.2f} for sunspot forecast.")

"""### Save the Model"""

model.save('rnn_model.h5')

model.save('save_model/my_model')

!tar -czvf save_model.tar.gz save_model/

"""<h1>Contact Me</h1>
<p>If you have something to say to me please contact me:</p>

<ul>
  <li>Twitter: <a href="https://twitter.com/Doguilmak">Doguilmak</a></li>
  <li>Mail address: doguilmak@gmail.com</li>
</ul>
"""

from datetime import datetime
print(f"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")